# Import Streamlit for the web UI.
import streamlit as st
# Import the official OpenAI helper.
from openai import OpenAI
# Import PDF reader and inâ€‘memory byte stream.
import PyPDF2, io


# â”€â”€ Page header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title('ğŸ’¬ PDFâ€‘awareÂ Chatbot')                                    # Visible page title.
st.write(                                                           # Short instructions.
    'Ask anything about an uploadedâ€¯PDF.Â Â \n'
    'You need anÂ OpenAI API key â€“Â get one '
    '[here](https://platform.openai.com/account/api-keys).'
)


# â”€â”€ API key â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
openai_api_key = st.text_input('OpenAI APIÂ Key', type='password')   # Hidden key box.
if not openai_api_key:                                             # Stop if empty.
    st.info('Please add yourÂ OpenAI API key to continue.', icon='ğŸ—ï¸')
    st.stop()

client = OpenAI(api_key=openai_api_key)                             # Create client.


# â”€â”€ PDF upload & caching â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
pdf_file = st.file_uploader('ğŸ“„Â Upload aâ€¯PDF to chat about', type='pdf')  # Upload.

# Read the PDF once, store its text in session_state.
if pdf_file and 'doc_text' not in st.session_state:
    reader   = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))        # Parse bytes.
    pages    = [p.extract_text() or '' for p in reader.pages]       # Text per page.
    fulltext = '\n'.join(pages)                                     # Join pages.
    st.session_state.doc_text = fulltext                            # Cache.
    st.success(f'LoadedÂ {len(pages)}Â page(s).')                     # Confirmation.

# Optional preview of the extracted text.
if 'doc_text' in st.session_state:
    with st.expander('Preview extracted text', expanded=False):
        st.write(st.session_state.doc_text[:2000] + 'â€¦')            # FirstÂ 2â€¯kÂ chars.


# â”€â”€ Chat history â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if 'messages' not in st.session_state:                              # First run.
    st.session_state.messages = []                                  # Init history.

# Render past conversation.
for m in st.session_state.messages:
    with st.chat_message(m['role']):
        st.markdown(m['content'])


# â”€â”€ User input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
prompt = st.chat_input('Ask a question about theÂ PDFâ€¦')             # Chat box.
if not prompt:                                                      # No input yet.
    st.stop()

# Store and display the new user message.
st.session_state.messages.append({'role': 'user', 'content': prompt})
with st.chat_message('user'):
    st.markdown(prompt)


# â”€â”€ Build context for the model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
context = []                                                        # Fresh list.

# Add document excerpt as a system message (only if a PDF is loaded).
if 'doc_text' in st.session_state:
    doc_excerpt = st.session_state.doc_text[:12000]                 # Trim for cost.
    context.append({
        'role': 'system',
        'content': (
            'You are a helpful assistant that responds in rap lyricsÂ \n'
            'Answer the user strictly using the information in this document:\n'
            + doc_excerpt
        )
    })

# Append the running chat history.
context.extend(
    {'role': m['role'], 'content': m['content']}
    for m in st.session_state.messages
)


# â”€â”€ Model call with streaming â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.chat_message('assistant'):                                  # Display area.
    stream = client.chat.completions.create(                        # Request GPTâ€‘3.5.
        model='gpt-3.5-turbo',
        messages=context,
        stream=True,
    )
    reply = st.write_stream(stream)                                 # Show tokens live.

# Save assistant reply.
st.session_state.messages.append({'role': 'assistant', 'content': reply})